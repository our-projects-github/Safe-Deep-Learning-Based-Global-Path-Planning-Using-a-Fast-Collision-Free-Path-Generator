# -*- coding: utf-8 -*-
"""ai2thortrain.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ab5JJOctg9mvUcF-VDy2f3uRxt-lD3SQ
"""

import random
import matplotlib.path as mplPath
import time
import numpy as np
import tensorflow as tf
from keras import optimizers
import keras
import ai2thorloss as ailoss
import ai2thormodel as aimodel
import ai2thorprocessdata as aipdata

def train(map_name,num_data,obstacle_path, data_path, batch_size, epochs, loss="mse_ner", process_data="step", hid=256, stacked_hidden_layers=4, lr=0.5, alpha=1000., pow_val=20.):
  loss_name = loss  
  object_c = ailoss.format_obstacles(load_poly=obstacle_path)

  obs_side_A, obs_side_B = ailoss.sides(obstacle_path)

  if loss == "mse_ner":
    loss = ailoss.mse_ner(obs_side_A, obs_side_B, alpha , pow_val)
  elif loss == "mse":
    loss = ailoss.mse((object_c))


  if process_data == "normal":
      trainingData = aipdata.ProcessData(filename=data_path)
      train_X, train_Y = trainingData.formatData(print_shapes=True)

  elif process_data == "random":
    trainingData = aipdata.ProcessData_add(filename=data_path)
    train_X, train_Y = trainingData.formatData(print_shapes=True, add_points = 5)

  elif process_data == "step":
    trainingData = aipdata.ProcessData_step(filename=data_path)
    train_X, train_Y = trainingData.formatData(print_shapes=True ,dis_step = 10. )


  inp_dim = train_X.shape[-1]
  op_dim = train_Y.shape[-1]

  model = aimodel.SimpleRNN(hid=hid, inp_dim=inp_dim, op_dim=op_dim, stacked_lstm_layers=stacked_hidden_layers)
  adadelta = tf.keras.optimizers.Adadelta(lr=lr)
  model.summary()

  model.compile(loss = loss, optimizer=adadelta, metrics=['accuracy'])

  model.fit(train_X, train_Y, batch_size , epochs, verbose=1, validation_split=0.1, shuffle=True)
  model_name = map_name+'_'+str(num_data)+'data_'+loss_name+"_"+ process_data +"_"+"MODEL"

  from keras.models import model_from_json
  # serialize model to JSON
  model_json = model.to_json()
  with open(model_name + ".json", "w") as json_file:
    json_file.write(model_json)
  # serialize weights to HDF5
  model.save_weights(model_name +".h5")
  print("Saved model to disk")

  data = []
  data.append(model_name)

  file = open('model_name.txt','w')
  for item in data:
     file.write(item+"\n")
  file.close()