# -*- coding: utf-8 -*-
"""Copy of walk path.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14cB2v1TJB-DZGDxhcySJel-k-1quJ2f8
"""

# def get_inputs(map_name,path_file,xmax,zmax,):
#   map_name = input('map_name: ')
#   path_file = input('map_name: ')
#   xmax = input('map_name: ')
#   zmax = input('map_name: ')

def txt2list(file_name):

  # opening the file in read mode
  my_file = open(file_name, "r")
    
  # reading the file
  data = my_file.read()
    
  # replacing end of line('/n') with ' ' and
  # splitting the text it further when '.' is seen.
  data_into_list = data.split('\n' )
    
  data_into_list=data_into_list[:-1]
  print(data_into_list)

  my_file.close()
  return data_into_list

# FILE = input('Give me the name of inputs txt file : ')
# if FILE.count(".txt")==0:
#   FILE = FILE + '.txt'

input('press Enter to start! ')

import os

FILE = "AI_inputs.txt"
cond = 0
while cond== 0:
  try:
    inputs = txt2list(FILE)
    cond = 1
  except:
    os.chdir("ai2thor_files")

map_name , path_file , xmax , zmax = inputs

xmax = int(xmax)
zmax = int(zmax)

"""# Installation

âš¡ _Note_: AI2-THOR often runs significantly _slower_ using Colab's runtime than it does with a local runtime. However, in many cases, it is nice to explore without installing anything locally and not all devices are compatible with running AI2-THOR (e.g., Windows devices, tables, phones).
"""

# !pip install --upgrade ai2thor ai2thor-colab &> /dev/null
import ai2thor
import ai2thor_colab

from ai2thor.controller import Controller
from ai2thor_colab import (
    plot_frames,
    show_objects_table,
    side_by_side,
    overlay,
    show_video
)

import matplotlib.pyplot as plt
import numpy as np
import os

ai2thor_colab.start_xserver()

"AI2-THOR Version: " + ai2thor.__version__

controller = Controller(scene = map_name)


size_x = controller.last_event.metadata['sceneBounds']["size"]["x"]
size_z = controller.last_event.metadata['sceneBounds']["size"]["z"]

desired_size =700
cam_x = desired_size
cam_z = (size_z/size_x) * cam_x
if cam_z> desired_size :
  cam_z = desired_size
  cam_x = (size_x/size_z) * cam_z

X = np.array(controller.last_event.metadata['sceneBounds']["cornerPoints"])[:,0]
Z = np.array(controller.last_event.metadata['sceneBounds']["cornerPoints"])[:,2]
Y = np.array(controller.last_event.metadata['sceneBounds']["cornerPoints"])[:,1]

OUTER_x = np.array([X[0], X[1], X[-1], X[-2] , X[0] ])
OUTER_z = np.array([ Z[0], Z[1], Z[-1], Z[-2] ,Z[0] ])


agent_x = controller.last_event.metadata["agent"]["position"]["x"]
agent_z = controller.last_event.metadata["agent"]["position"]["z"]
agent_y = controller.last_event.metadata["agent"]["position"]["y"]

# controller.reset()

controller = Controller(scene = map_name, renderSemanticSegmentation=True, save_image_per_frame=True , gridSize=0.01 ,width=cam_x, height=cam_z)

"""#walk trough viapoints

##path points
"""

# np.savetxt("/content/drive/MyDrive/AI2THOR/temp_path/temp_path.txt", POINT, fmt="%s")
POINT = np.loadtxt( path_file )



POINT

X_before = POINT[:, 0]
Y_before = POINT[:, 1]

X_network_max = xmax
Z_network_max = zmax

x = (size_x/X_network_max) * X_before + OUTER_x.min()
# x= x + np.random.uniform(0,0.00001 , len(x))
y = (size_z/Z_network_max) * (Z_network_max - Y_before) + OUTER_z.min()

"""## walk_point_ang"""

import numpy as np
def get_angle(p0, p1=np.array([0,0]), p2=None):
    ''' compute angle (in degrees) for p0p1p2 corner
    Inputs:
        p0,p1,p2 - points in the form of [x,y]
    '''
    if p2 is None:
        p2 = p1 + np.array([1, 0])
    v0 = np.array(p0) - np.array(p1)
    v1 = np.array(p2) - np.array(p1)

    angle = np.math.atan2(np.linalg.det([v0,v1]),np.dot(v0,v1))
    return np.degrees(angle)


p = zip(x,y)
# p = np.array( list(p)[2] )
p = list(p)

ang_final=[]
for i in range(len(p)-2):
  p0=np.array( p[i] )
  p1=np.array( p[i+1] )
  p2=np.array( p[i+2] )
  # print(p0)
  # print(p1)
  # print(p2)

  # print(-1 * (180. + get_angle(p0, p1,p2)))
  ang_temp = -1 * (180. + get_angle(p0, p1,p2))
  ang_final.append(ang_temp)

# ang_final.append(0.)
#

p0_virtual = p[0] - np.array( [0. , .01 ] )
p0_virtual = p0_virtual.tolist()
init_angle = -1 * (180. + get_angle(  p0_virtual , p[0] , p[1] ))

while init_angle < 0. or  init_angle >= 360. :
  if init_angle< 0.:
    init_angle= init_angle + 360.
  if init_angle> 360.:
    init_angle= init_angle - 360.

init_angle

init_teleport = [ np.array(np.round( p[0] , 2 )) , np.round(init_angle , 0 ) ]

init_teleport

len(p)

"""##walk and show video"""

controller.reset()
controller = Controller(scene = map_name, renderSemanticSegmentation=True, save_image_per_frame=True , gridSize=0.01 ,width=cam_x, height=cam_z)

controller.step(action="GetMapViewCameraProperties")

third_camera_angle = 0
#----------------------------------------------------------------------------
if third_camera_angle == 0:
    # vertical
    controller.step(
        action="AddThirdPartyCamera",
        position=dict(x=X.mean(), y=Y.max(), z=Z.mean()),
        rotation=dict(x=90, y=0, z=0),
        orthographic=True,
        orthographicSize=(Y.max()+.24),   
    )

    #----------------------------------------------------------------------------
if third_camera_angle == 1:
    # horizontal 1
    controller.step(
        action="AddThirdPartyCamera",
        position=dict(x=X.mean(), y=Y.mean() , z=Z.min()+.1 ),
        rotation=dict(x=0, y= 0  , z=0),
    )

    # ---------------------------------------------------------------------------
if third_camera_angle == 2:
    # horizontal 2
    controller.step(
        action="AddThirdPartyCamera",
        position=dict(x=X.max()-2.3, y=Y.mean() , z=Z.mean() ),
        rotation=dict(x=0, y= 270  , z=0),
    )

"fadfad_abc".replace("_abc","")

frames = []
frames_eye = []
frames_segmentation = []



x_list=[]
z_list=[]
for i in range(len(p)-1):

    if i == 0:
        controller.step(
        action="Teleport",
        position=dict(x= init_teleport[0][0] , y= agent_y , z = init_teleport[0][1] ),
        rotation=dict(x=0, y= init_teleport[1] , z=0),
        standing=True)
        print(controller.last_event.metadata["lastActionSuccess"])
        print( "init pos:", init_teleport[0] ,"\tinit ang:",init_teleport[1] )
        frames.append( controller.last_event.third_party_camera_frames[-1] )
        frames_eye.append( controller.last_event.frame )
        frames_segmentation.append( controller.last_event.third_party_semantic_segmentation_frames[-1] )


    x_list.append( controller.last_event.metadata["agent"]["position"]["x"] )
    z_list.append( controller.last_event.metadata["agent"]["position"]["z"] )

    current_x = x_list[-1]
    current_z = z_list[-1]


    dist = np.sqrt( ( p[i+1][1] - current_z )**2 + ( p[i+1][0] - current_x )**2 )
    dist = np.round( dist , 2 )


    if i == 0:
        rot = 0.

    if i>0:
        past_x = x_list[-2]
        past_z = z_list[-2]

        p0=np.array( [ past_x , past_z ] )
        p1=np.array( [ current_x , current_z ] )
        p2=np.array( p[i+1] )
        rot = -1 * (180. + get_angle(p0, p1,p2))
        while rot < -180. or  rot >= 180. :
          if rot < -180.:
            rot = rot + 360.
          if rot > 180.:
            rot = rot - 360.
        rot = np.round(rot , 0 )

    print( i+1 ,"/", len(p)-1 ,"\tdist:",dist, "\trotate:", rot )
    
    if rot != 0 :
      controller.step(
          action="RotateRight",
          degrees = rot
      )
      print(controller.last_event.metadata["lastActionSuccess"])
    # if rot < 0 :
    #   controller.step(
    #       action="RotateLeft",
    #       degrees = rot
    #   )
      # print(controller.last_event.metadata["lastActionSuccess"])
    frames.append( controller.last_event.third_party_camera_frames[-1] )
    frames_eye.append( controller.last_event.frame )
    frames_segmentation.append( controller.last_event.third_party_semantic_segmentation_frames[-1] )

    controller.step(
        action="MoveAhead" ,
        moveMagnitude = dist )
    print(controller.last_event.metadata["lastActionSuccess"])
    
    frames.append( controller.last_event.third_party_camera_frames[-1] )
    frames_eye.append( controller.last_event.frame )
    frames_segmentation.append( controller.last_event.third_party_semantic_segmentation_frames[-1] )


controller.step(action="Done")

desired_final = (size_x/X_network_max) * POINT[-1][0] + OUTER_x.min() , (size_z/Z_network_max) * (Z_network_max - POINT[-1][1]) + OUTER_z.min()

reached_final = controller.last_event.metadata["agent"]["position"]["x"] , controller.last_event.metadata["agent"]["position"]["z"] 

error = np.sqrt( np.sum(np.square(np.array(desired_final) - np.array(reached_final))) )

print("goal =", desired_final)
print("reached_final =", reached_final)
print("error :",error )


import os

show_video(frames, fps= 2 )
os.rename("__temp__.mp4", "top_view.mp4")


show_video(frames_eye, fps= 2 )
os.rename("__temp__.mp4", "robot_eye_view.mp4")


show_video(frames_segmentation, fps= 2 )
os.rename("__temp__.mp4", "top_view_segment.mp4")




plt.figure(figsize=( 30 , (cam_z/cam_x)*30  ) )
plt.imshow( controller.last_event.third_party_camera_frames[-1]  )

#maxy
# plt.figure(figsize=(15,15))
plt.figure(figsize=( 30 , (cam_z/cam_x)*30  ) )
plt.imshow( controller.last_event.third_party_camera_frames[-1] , aspect='auto',zorder=0,extent=[X.min(), X.max(),Z.min(),Z.max()] )

agent_x = controller.last_event.metadata["agent"]["position"]["x"]
agent_z = controller.last_event.metadata["agent"]["position"]["z"]
plt.scatter(agent_x,agent_z,c="red",marker="+",s=500)

object_data = controller.last_event.metadata['objects']

object_list= [47 , 39 , 45,46,4,37,40 ]
object_data = controller.last_event.metadata['objects']
#laptop

for x in object_list:
  plt.scatter( object_data[ x ]["position"]["x"],	object_data[ x ]["position"]["z"] , c="gold")
  plt.text(  object_data[ x ]["position"]["x"],	object_data[ x ]["position"]["z"], object_data[ x ]['assetId'] , horizontalalignment='right', verticalalignment='bottom' )
  print(object_data[ x ]['assetId'])

plt.scatter(X.max(),Z.max(),s=100,marker="o")
plt.show()

